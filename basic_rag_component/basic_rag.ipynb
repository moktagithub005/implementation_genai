{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "798f4fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load your env variables \n",
    "\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11fa8203",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load your api key\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ['LANGCHAIN_API_KEY']=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_PROJECT']=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ['LANGCHAIN_TRACING_V2']=\"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1c9d659",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load openai GPT model\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model='gpt-4o')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3352695f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001BA621CE5F0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001BA621FC700> root_client=<openai.OpenAI object at 0x000001BA5F435C00> root_async_client=<openai.AsyncOpenAI object at 0x000001BA621CE650> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c2a2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ask some question \n",
    "result=llm.invoke(\"what is generative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2584281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The term \"generative\" refers to the capability or process of producing or creating something. In the context of technology and artificial intelligence, \"generative\" often refers to models or algorithms that can create new content. Here are a few examples:\\n\\n1. **Generative Models in AI**: These are algorithms that can generate new data instances that resemble a given dataset. Popular types of generative models include Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and Transformer-based models. They are used in various applications such as creating realistic images, videos, text, or music.\\n\\n2. **Generative Design**: In design and engineering, generative design refers to using algorithms to automatically produce a wide range of design solutions based on constraints and variables defined by the designer. This process can lead to highly optimized and innovative designs.\\n\\n3. **Generative Art**: This is art created autonomously by a system, often using algorithms and computational processes. Artists use generative techniques to create complex, emergent forms of art that may evolve or change over time.\\n\\n4. **Generative Grammar**: In linguistics, generative grammar is a theory of grammar that aims to describe the implicit knowledge that humans have about the structure and formation of sentences in their language.\\n\\nIn essence, \"generative\" implies the generation of new and often original content, structures, or concepts through computational or algorithmic means.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 290, 'prompt_tokens': 11, 'total_tokens': 301, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None} id='run--61af6fb7-b9b2-4cf0-8003-b6898f824c1c-0' usage_metadata={'input_tokens': 11, 'output_tokens': 290, 'total_tokens': 301, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "51b76d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build a prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are an expert in AI Engineerig\"),\n",
    "    (\"user\",\"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ae54fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6a5e499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='LangSmith is a tool developed by LangChain that assists developers in building, monitoring, and evaluating applications that utilize large language models (LLMs). It is designed to support the efforts of developers in creating high-quality, reliable, and efficient applications that leverage the capabilities of LLMs.\\n\\nHere are some key features and components of LangSmith:\\n\\n1. **Streamlining Development**: LangSmith provides developers with tools to experiment with different model configurations, track changes, and evaluate the performance of models over time. This helps in faster prototyping and iteration.\\n\\n2. **Monitoring**: The platform offers monitoring capabilities which are crucial for understanding how an application is performing in real-time. This includes tracking key performance indicators, understanding user interactions, and spotting potential issues or anomalies.\\n\\n3. **Evaluation**: LangSmith has features to evaluate the effectiveness and accuracy of language models. It provides insights into model performance, helping developers refine and optimize their applications based on empirical data.\\n\\n4. **Integration with LangChain**: As part of the LangChain ecosystem, LangSmith is designed to seamlessly integrate with other tools and libraries within the ecosystem, allowing developers to build robust and scalable applications.\\n\\n5. **User-Friendly Interface**: The platform offers an intuitive user interface that simplifies the complexities involved in working with large language models, making it more accessible to developers who may not have extensive experience in machine learning.\\n\\n6. **Support for Multiple Models**: LangSmith supports a range of language models, allowing developers to choose and switch between different models depending on their specific needs and the nature of their applications.\\n\\nOverall, LangSmith is an essential tool for developers working in the space of AI and natural language processing, providing them with the resources needed to effectively build and manage applications that make use of large language models.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 357, 'prompt_tokens': 26, 'total_tokens': 383, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_55d88aaf2f', 'finish_reason': 'stop', 'logprobs': None} id='run--eac95900-43c8-4fab-94ed-c2639d6ba6ae-0' usage_metadata={'input_tokens': 26, 'output_tokens': 357, 'total_tokens': 383, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## ask the question via prompt + model chain\n",
    "response=chain.invoke({\"input\":\"can you tell me about langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc6061cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90bba9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use an output parser to clean the answer\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1c05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a11d24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Of course! I'm an AI developed by OpenAI, designed to assist users by providing information, answering questions, and performing a wide range of tasks. My capabilities include understanding and generating text based on the input I'm given, which allows me to assist with a variety of topics such as technology, science, language, and more. My knowledge is based on a diverse dataset that includes information up until October 2023, although I cannot access real-time or proprietary data. I'm here to help with explanations, advice, and any topics you're curious about. Let me know how I can assist you today!\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 119, 'prompt_tokens': 25, 'total_tokens': 144, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'finish_reason': 'stop', 'logprobs': None} id='run--198c4c2d-682d-4f87-b030-a250b430303d-0' usage_metadata={'input_tokens': 25, 'output_tokens': 119, 'total_tokens': 144, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"can you tell me about you\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad963e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
